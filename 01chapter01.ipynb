{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be4c38c9-0010-487c-ab37-ef6c1730e411",
   "metadata": {},
   "source": [
    "# 0.0.0 前言——成书缘由\n",
    "作者首先解释道：\n",
    "任何一种计算技术要想发挥其全部影响力，都必须得到充分的理解、充分的文档记录，并得到成熟的、维护良好的工具的支持。关键思想应该被清楚地提炼出来，尽可能减少需要让新的从业者跟上时代的入门时间。\n",
    "\n",
    "测试深度学习的潜力带来了独特的挑战，因为任何一个应用都会将不同的学科结合在一起。应用深度学习需要同时了解（1）以特定方式提出问题的动机；（2）给定建模方法的数学；（3）将模型拟合数据的优化算法；（4）能够有效训练模型、克服数值计算缺陷并最大限度地利用现有硬件的工程方法。同时教授表述问题所需的批判性思维技能、解决问题所需的数学知识，以及实现这些解决方案所需的软件工具，这是一个巨大的挑战。\n",
    "\n",
    "在我们开始写这本书的时候，没有资源能够同时满足一些条件：（1）是最新的；（2）涵盖了现代机器学习的\n",
    "所有领域，技术深度丰富；（3）在一本引人入胜的教科书中，人们可以在实践教程中找到干净的可运行代码，\n",
    "并从中穿插高质量的阐述。我们发现了大量关于如何使用给定的深度学习框架（例如，如何对TensorFlow中\n",
    "的矩阵进行基本的数值计算)或实现特定技术的代码示例（例如，LeNet、AlexNet、ResNet的代码片段），这\n",
    "些代码示例分散在各种博客帖子和GitHub库中。但是，这些示例通常关注如何实现给定的方法，但忽略了为\n",
    "什么做出某些算法决策的讨论。\n",
    "\n",
    "虽然一些互动资源已经零星地出现以解决特定主题。例如，在网站Distill1上发布的引人入胜的博客帖子或个人博客，但它们仅覆盖深度学习中的选定主题，并且通常缺乏相关代码。另一方面，虽然已经出现了几本教科书，其中最著名的是(Goodfellow et al., 2016)（中文名《深度学习》），它对深度学习背后的概念进行了全面的调查，但这些资源并没有将这些概念的描述与这些概念的代码实现结合起来。有时会让读者对如何实现它们一无所知。此外，太多的资源隐藏在商业课程提供商的付费壁垒后面。\n",
    "\n",
    "我们着手创建的资源可以：（1）每个人都可以免费获得；（2）提供足够的技术深度，为真正成为一名应用机\n",
    "器学习科学家提供起步；（3）包括可运行的代码，向读者展示如何解决实践中的问题；（4）允许我们和社区\n",
    "的快速更新;（5）由一个论坛2作为补充，用于技术细节的互动讨论和回答问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ca4531-e690-465f-8501-248af4a319d4",
   "metadata": {},
   "source": [
    "# 0.1.0 其他提及的资料（在本仓库的resource文件夹中）\n",
    "Chris Bishop的优秀教科书(Bishop, 2006，Pattern-Recognition-and-Machine-Learning)，对每个主题都教得很透彻，以至于要读到线性回归这一章需要大量的工作。虽然专家们喜欢这本书正是因为它的\n",
    "透彻性，但对初学者来说，这一特性限制了它作为介绍性文本的实用性。\n",
    "Bela Bollobas的《线性分析》(Bollobás, 1999) 对线性代数和函数分析进行了深入的研究。All of statistics(Wasserman, 2013) 是一本很好的统计学指南。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7fbcaa-2949-4e35-a1f6-9b85729aff53",
   "metadata": {},
   "source": [
    "## 官方配套代码下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ade384-73bc-4ac8-85f3-111f091fe733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !curl https://zh-v2.d2l.ai/d2l-zh-2.0.0.zip -o d2l-zh.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f66cf8b-1493-4040-9200-1c955f273507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch==2.0.0 torchvision==0.15.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b4aab4-a18a-4ab5-8e27-8399cebb1166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install d2l==1.0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7335ad91-97d7-4c60-8ca0-3344eccbff98",
   "metadata": {},
   "source": [
    "# 1.1.0 关于模型、参数和训练的解释\n",
    "利用机器学习算法，我们不需要设计一个“明确地”识别唤醒词的系统。相反，我们只需要定义一个灵活的\n",
    "程序算法，其输出由许多参数（parameter）决定，然后使用数据集来确定当下的“最佳参数集”，这些参数\n",
    "通过某种性能度量方式来达到完成任务的最佳性能。\n",
    "那么到底什么是参数呢？参数可以被看作旋钮，旋钮的转动可以调整程序的行为。任一调整参数后的程序被\n",
    "称为模型（model）。通过操作参数而生成的所有不同程序（输入‐输出映射）的集合称为“模型族”。使用数\n",
    "据集来选择参数的元程序被称为学习算法（learning algorithm）。\n",
    "在开始用机器学习算法解决问题之前，我们必须精确地定义问题，确定输入（input）和输出（output）的性\n",
    "质，并选择合适的模型族。\n",
    "在机器学习中，学习（learning）是一个训练模型的过程。通过这个过程，我们可以发现正确的参数集，\n",
    "从而使模型强制执行所需的行为。换句话说，我们用数据训练（train）模型。\n",
    "\n",
    "训练过程通常\n",
    "包含如下步骤：\n",
    "1. 从一个随机初始化参数的模型开始，这个模型基本没有“智能”；\n",
    "2. 获取一些数据样本（例如，音频片段以及对应的是或否标签）；\n",
    "3. 调整参数，使模型在这些样本中表现得更好；\n",
    "4. 重复第（2）步和第（3）步，直到模型在任务中的表现令人满意。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf8a327-182e-4456-8472-e3e3b5d861e0",
   "metadata": {},
   "source": [
    "![imag](./img/00chapter-01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af987fee-aea4-41cf-9658-eb9fa7d68f7e",
   "metadata": {},
   "source": [
    "## 1.1.1 机器学习中的关键组件\n",
    "无论什么类型的机器学习问题，都会遇到这些组件：\n",
    "1. 可以用来学习的数据（data）；\n",
    "2. 如何转换数据的模型（model）；\n",
    "3. 一个目标函数（objective function），用来量化模型的有效性；\n",
    "4. 调整模型参数以优化目标函数的算法（algorithm）。\n",
    "\n",
    "### 数据\n",
    "每个数据集由一个个样本（example, sample）组成，\n",
    "大多时候，它们遵循独立同分布(independently and identically distributed, i.i.d.)。样本有时也叫做数据点\n",
    "（data point）或者数据实例（data instance），通常每个样本由一组称为特征（features，或协变量（covariates））的属性组成。机器学习模型会根据这些属性进行预测。在上面的监督学习问题中，要预测的是一个特殊的属性，它被称为标签（label，或目标（target））。\n",
    "\n",
    "当每个样本的特征类别数量都是相同的时候，其特征向量是固定长度的，这个长度被称为数据的维数（dimensionality）。固定长度的特征向量是一个方便的属性，它可以用来量化学习大量样本。\n",
    "\n",
    "与传统机器学习方法相比，深度学习的一个主要优势是可以处理不同长度的数据。一般来说，拥有越多数据的时候，工作就越容易。更多的数据可以被用来训练出更强大的模型，从而减少对预先设想假设的依赖。数据集的由小变大为现代深度学习的成功奠定基础。在没有大数据集的情况下，许多令人兴奋的深度学习模型黯然失色。就算一些深度学习模型在小数据集上能够工作，但其效能并不比传统方法高。\n",
    "\n",
    "请注意，仅仅拥有海量的数据是不够的，我们还需要正确的数据。如果数据中充满了错误，或者如果数据的\n",
    "特征不能预测任务目标，那么模型很可能无效。有一句古语很好地反映了这个现象：“输入的是垃圾，输出的\n",
    "也是垃圾。”（“Garbage in, garbage out.”）此外，糟糕的预测性能甚至会加倍放大事态的严重性。在一些敏\n",
    "感应用中，如预测性监管、简历筛选和用于贷款的风险模型，我们必须特别警惕垃圾数据带来的后果。\n",
    "\n",
    "一种常见的问题来自不均衡的数据集，比如在一个有关医疗的训练数据集中，某些人群没有样本表示。\n",
    "\n",
    "当数据不具有充分代表性，甚至包含了一些社会偏见时，模型就很有可能有偏见。\n",
    "\n",
    "### 模型\n",
    "深度学习与经典方法的区别主要在于：前者关注的功能强大的模型，这些模型由神经网络错综复杂的交织在一起，包含层层数据转换，因此被称为深度学习（deep learning）。\n",
    "\n",
    "### 目标函数\n",
    "机器学习是“从经验中学习”的。这里所说的“学习”，是指自主提高模型完成某些任务的效能。\n",
    "但是，什么才算真正的提高呢？在机器学习中，我们需要定义模型的优劣程度的度量，这个度量在大多数情况是“可优化”的，这被称之为目标函数（objective function）。我们通常定义一个目标函数，并希望优化它到最低点。因为越低越好，所以这些函数有时被称为损失函数（loss function，或cost function）。\n",
    "但这只是一个惯例，我们也可以取一个新的函数，优化到它的最高点。\n",
    "这两个函数本质上是相同的，只是翻转一下符号。\n",
    "\n",
    "当任务在试图预测数值时，最常见的损失函数是平方误差（squared error），即预测值与实际值之差的平方。\n",
    "当试图解决分类问题时，最常见的目标函数是最小化错误率，即预测与实际情况不符的样本比例。有些目标\n",
    "函数（如平方误差）很容易被优化，有些目标（如错误率）由于不可微性或其他复杂性难以直接优化。在这\n",
    "些情况下，通常会优化替代目标。\n",
    "\n",
    "通常，损失函数是根据模型参数定义的，并取决于数据集。在一个数据集上，我们可以通过最小化总损失来\n",
    "学习模型参数的最佳值。该数据集由一些为训练而收集的样本组成，称为训练数据集（training dataset，或\n",
    "称为训练集（training set））。然而，在训练数据上表现良好的模型，并不一定在“新数据集”上有同样的性\n",
    "能，这里的“新数据集”通常称为测试数据集（test dataset，或称为测试集（test set））。\n",
    "综上所述，可用数据集通常可以分成两部分：训练数据集用于拟合模型参数，测试数据集用于评估拟合的模\n",
    "型。然后我们观察模型在这两部分数据集的性能。“一个模型在训练数据集上的性能”可以被想象成“一个学\n",
    "生在模拟考试中的分数”。这个分数用来为一些真正的期末考试做参考，即使成绩令人鼓舞，也不能保证期\n",
    "末考试成功。换言之，测试性能可能会显著偏离训练性能。当一个模型在训练集上表现良好，但不能推广到\n",
    "测试集时，这个模型被称为过拟合（overfitting）的。就像在现实生活中，尽管模拟考试考得很好，真正的考\n",
    "试不一定百发百中。\n",
    "\n",
    "### 优化算法\n",
    "当我们获得了一些数据源及其表示、一个模型和一个合适的损失函数，接下来就需要一种算法，它能够搜索出\n",
    "最佳参数，以最小化损失函数。深度学习中，大多流行的优化算法通常基于一种基本方法–梯度下降（gradient\n",
    "descent）。简而言之，在每个步骤中，梯度下降法都会检查每个参数，看看如果仅对该参数进行少量变动，训\n",
    "练集损失会朝哪个方向移动。然后，它在可以减少损失的方向上优化参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560e6800-ce16-48c2-a971-28966d81bc50",
   "metadata": {},
   "source": [
    "## 1.3.1 监督学习\n",
    "监督学习的学习过程一般可以分为三大步骤：\n",
    "1. 从已知大量数据样本中随机选取一个子集，为每个样本获取真实标签。有时，这些样本已有标签（例如，\n",
    "患者是否在下一年内康复？）；有时，这些样本可能需要被人工标记（例如，图像分类）。这些输入和相\n",
    "应的标签一起构成了训练数据集；\n",
    "2. 选择有监督的学习算法，它将训练数据集作为输入，并输出一个“已完成学习的模型”；\n",
    "3. 将之前没有见过的样本特征放到这个“已完成学习的模型”中，使用模型的输出作为相应标签的预测。\n",
    "\n",
    "### 回归\n",
    "回归（regression）是最简单的监督学习任务之一。\n",
    "判断回归问题的一个很好的经验法则是，任何有关“有多少”的问题很可能就是回归问题。比如：\n",
    "• 这个手术需要多少小时；\n",
    "• 在未来6小时，这个镇会有多少降雨量。\n",
    "但一些差异是由于两个特征之外的几个因素造成的。在这些情况下，我们将尝试学习最小化“预测值和实际标签值的差异”的模型。本书大部分章节将关注平方误差损失函数的最小化。\n",
    "\n",
    "### 分类\n",
    "分类问题希望模型能够预测样本属于哪个类别（category，正式称为类（class））。“哪一个”的问题叫做分类（classification）问题。当有两个以上的类别时，我们把这个问题称为多项分类（multiclass classification）问题。与解决回归问题不同，分类问题的常见损失函数被称为交叉熵（crossentropy）。\n",
    "\n",
    "回归是训练一个回归函数来输出一个数值；分类是训练一个分类器来输出预测的类别。\n",
    "\n",
    "分类可能变得比二项分类、多项分类复杂得多。例如，有一些分类任务的变体可以用于寻找层次结构，层次\n",
    "结构假定在许多类之间存在某种关系。因此，并不是所有的错误都是均等的。人们宁愿错误地分入一个相关\n",
    "的类别，也不愿错误地分入一个遥远的类别，这通常被称为层次分类(hierarchical classification)。早期的一个例子是卡尔·林奈13，他对动物进行了层次分类。\n",
    "\n",
    "### 标记问题\n",
    "\n",
    "学习预测不相互排斥的类别的问题称为多标签分类（multi‐label classification）。\n",
    "\n",
    "### 搜索\n",
    "如果要求我们输出字\n",
    "母表中的前5个字母，返回“A、B、C、D、E”和“C、A、B、E、D”是不同的。即使结果集是相同的，集内的顺序有时却很重要。\n",
    "该问题的一种可能的解决方案：首先为集合中的每个元素分配相应的相关性分数，然后检索评级最高的元素。\n",
    "PageRank，谷歌搜索引擎背后最初的秘密武器就是这种评分系统的早期例子，但它的奇特之处在于它不依赖于实际的查询。在这里，他们依靠一个简单的相关性过滤来识别一组相关条目，然后根据PageRank对包含查询条件的结果进行排序。如今，搜索引擎使用机器学习和用户行为模型来获取网页相关性得分。\n",
    "\n",
    "### 推荐系统\n",
    "另一类与搜索和排名相关的问题是推荐系统（recommender system），它的目标是向特定用户进行“个性化”\n",
    "推荐。\n",
    "尽管推荐系统具有巨大的应用价值，但单纯用它作为预测模型仍存在一些缺陷。\n",
    "首先，我们的数据只包含“审查后的反馈”：用户更倾向于给他们感觉强烈的事物打分。\n",
    "此外，推荐系统有可能形成反馈循环：推荐系统首先会优先推送一个购买量较大（可能被认为更好）的商品，然而目前用户的购买习惯往往是遵循推荐算法，但学习算法并不总是考虑到这一细节，进而更频繁地被推荐。综上所述，关于如何处理审查、激励和反馈循环的许多问题，都是重要的开放性研究问题。\n",
    "\n",
    "### 序列学习\n",
    "序列学习需要摄取输入序列或预测输出序列，或两者兼而有之。具体来说，输入和输出都是可变长度的序列，例如机器翻译和从语音中转录文本。\n",
    "标记和解析（这涉及到用属性注释文本序列）\n",
    "自动语音识别。在语音识别中，输入序列是说话人的录音（如图1.3.5 所示），输出序列是说话人所说内容的\n",
    "文本记录。\n",
    "文本到语音。这与自动语音识别相反。换句话说，输入是文本，输出是音频文件。\n",
    "机器翻译。在语音识别中，输入和输出的出现顺序基本相同。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930aecd0-3d35-47e6-9785-0aebd6b34c84",
   "metadata": {},
   "source": [
    "## 1.3.2 无监督学习\n",
    "\n",
    "数据中不含有“目标”的机器学习问题通常被为无监督学习（unsupervised learning）\n",
    "无监督学习可以回答：\n",
    "    - 聚类（clustering）问题：没有标签的情况下，我们是否能给数据分类\n",
    "    - 主成分分析（principal component analysis）问题：我们能否找到少量的参数来准确地捕捉数据的线\n",
    "性相关属性\n",
    "    - 因果关系（causality）和概率图模型（probabilistic graphical models）问题：我们能否描述观察到的\n",
    "许多数据的根本原因？例如，如果我们有关于房价、污染、犯罪、地理位置、教育和工资的人口统计数据，我们能否简单地根据经验数据发现它们之间的关系？\n",
    "    - 生成对抗性网络（generative adversarial networks）：为我们提供一种合成数据的方法，甚至像图像和音频这样复杂的非结构化数据。潜在的统计机制是检查真实和虚假数据是否相同的测试，它是无监督学习的另一个重要而令人兴奋的领域。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5754a420-eb10-445e-aa68-0b4c4333fb16",
   "metadata": {},
   "source": [
    "## 1.3.4 强化学习\n",
    "如果你对使用机器学习开发与环境交互并采取行动感兴趣，那么最终可能会专注于强化学习（reinforcementlearning）。这可能包括应用到机器人、对话系统，甚至开发视频游戏的人工智能（AI）。深度强化学习（deepreinforcement learning）将深度学习应用于强化学习的问题，是非常热门的研究领域。突破性的深度Q网络（Q‐network）在雅达利游戏中仅使用视觉输入就击败了人类，以及AlphaGo 程序在棋盘游戏围棋中击败了世界冠军，是两个突出强化学习的例子。\n",
    "在强化学习问题中，智能体（agent）在一系列的时间步骤上与环境交互。在每个特定时间点，智能体从环境接收一些观察（observation），并且必须选择一个动作（action），然后通过某种机制（有时称为执行器）将其传输回环境，最后智能体从环境中获得奖励（reward）。此后新一轮循环开始，智能体接收后续观察，并选择后续操作，依此类推。强化学习的过程在图1.3.7 中进行了说明。请注意，强化学习的目标是产生一个好的策略（policy）。强化学习智能体选择的“动作”受策略控制，即一个从环境观察映射到行动的功能。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75099e3b-f51e-486f-a123-e1b4d5b15d38",
   "metadata": {},
   "source": [
    "![image](../img/01chapter01_1_3_4强化学习和环境之间的相互作用.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ded374c-30db-4306-bb88-ba0d64bed118",
   "metadata": {},
   "source": [
    "在任何时间点上，强化学习智能体可能知道一个好的策略，但可能有许多更好的策略从未尝试过的。\n",
    "强化学习智能体必须不断地做出选择：是应该利用当前最好的策略，还是探索新的策略空间（放弃一些短期回报来换取知识）。[最后一句引人深思，是博弈也是机会成本的衡量]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5d7c29-a418-4e1f-8dc0-947e74d88ca4",
   "metadata": {},
   "source": [
    "为了解决各种各样的机器学习问题，深度学习提供了强大的工具。虽然许多深度学习方法都是最近才有重大突破，但使用数据和神经网络编程的核心思想已经研究了几个世纪。事实上，人类长期以来就有分析数据和预测未来结果的愿望，而自然科学大部分都植根于此。例如，伯努利分布是以雅各布•伯努利（1654‐1705）16命名的。而高斯分布是由卡尔•弗里德里希•高斯（1777‐1855）17发现的，他发明了最小均方算法，至今仍用于解决从保险计算到医疗诊断的许多问题。这些工具算法催生了自然科学中的一种实验方法——例如，电阻中电流和电压的欧姆定律可以用线性模型完美地描述。\n",
    "\n",
    "神经网络（neural networks）的得名源于生物灵感。一个多世纪以来（追溯到1873年亚历山大·贝恩和1890年詹姆斯·谢林顿的模型），研究人员一直试图组装类似于相互作用的神经元网络的计算电路。随着时间的推移，对生物学的解释变得不再肤浅，但这个名字仍然存在。其核心是当今大多数网络中都可以找到的几个关键原则：\n",
    "    - 线性和非线性处理单元的交替，通常称为层（layers）；\n",
    "    - 使用链式规则（也称为反向传播（backpropagation））一次性调整网络中的全部参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a09213-14d7-4d6a-b22a-a60e19fcb63c",
   "metadata": {},
   "source": [
    "深度学习的发展\n",
    "大约2010年开始，那些在计算上看起来不可行的神经网络算法变得热门起来，实际上是以下两点导致的：其一，随着互联网的公司的出现，为数亿在线用户提供服务，大规模数据集变得触手可及；另外，廉价又高质量的传感器、廉价的数据存储（克莱德定律）以及廉价计算（摩尔定律）的普及，特别是GPU的普及，使大规模算力唾手可得。\n",
    "\n",
    "随机存取存储器没有跟上数据增长的步伐。与此同时，算力的增长速度已经超过了现有数据的增长\n",
    "速度。这意味着统计模型需要提高内存效率（这通常是通过添加非线性来实现的），同时由于计算预算的增加，能够花费更多时间来优化这些参数。因此，机器学习和统计的关注点从（广义的）线性模型和核方法转移到了深度神经网络。这也造就了许多深度学习的中流砥柱，如多层感知机(McCulloch and Pitts, 1943) 、卷积神经网络(LeCun et al., 1998) 、长短期记忆网络(Graves and Schmidhuber, 2005) 和Q学习(Watkins andDayan, 1992) ，在相对休眠了相当长一段时间之后，在过去十年中被“重新发现”。\n",
    "下面列举了帮助研究人员在过去十年中取得巨大进步的想法（虽然只触及了皮毛）：\n",
    "    - 新的容量控制方法，如dropout (Srivastava et al., 2014)，有助于减轻过拟合的危险。\n",
    "    - 注意力机制解决了困扰统计学一个多世纪的问题：如何在不增加可学习参数的情况下增加系统的记忆和复杂性。\n",
    "    - 多阶段设计。\n",
    "    - 生成对抗网络(Goodfellow et al., 2014) 的发明。\n",
    "    - 在许多情况下，单个GPU不足以处理可用于训练的大量数据。在过去的十年中，构建并行和分布式训练算法的能力有了显著提高。设计可伸缩算法的关键挑战之一是深度学习优化的主力——随机梯度下降，它依赖于相对较小的小批量数据来处理。同时，小批量限制了GPU的效率。因此，在1024个GPU上进行训练，例如每批32个图像的小批量大小相当于总计约32000个图像的小批量。\n",
    "    - 并行计算的能力也对强化学习的进步做出了相当关键的贡献。\n",
    "    - 深度学习框架在传播思想方面发挥了至关重要的作用。允许轻松建模的第一代框架包括Caffe23、Torch24和Theano25。许多开创性的论文都是用这些工具写的。到目前为止，它们已经被TensorFlow26（通常通过其高级API Keras27使用）、CNTK28、Caffe 229和Apache MXNet30所取代。第三代工具，即用于深度学习的命令式工具，可以说是由Chainer31率先推出的，它使用类似于Python NumPy的语法来描述模型。这个想法被PyTorch32、MXNet的Gluon API33和Jax34都采纳了。\n",
    "\n",
    "“系统研究人员构建更好的工具”和“统计建模人员构建更好的神经网络”之间的分工大大简化了工作。例如，在2014年，对卡内基梅隆大学机器学习博士生来说，训练线性回归模型曾经是一个不容易的作业问题。而现在，这项任务只需不到10行代码就能完成，这让每个程序员轻易掌握了它。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9977cb47-7d7c-4ce8-9ca8-8d0b9470031d",
   "metadata": {},
   "source": [
    "深度学习的一个关键优势是它不仅取代了传统学习管道末端的浅层模型，而且还取代了劳动密集型的特征工程过程。此外，通过取代大部分特定领域的预处理，深度学习消除了以前分隔计算机视觉、语音识别、自然语言处理、医学信息学和其他应用领域的许多界限，为解决各种问题提供了一套统一的工具。\n",
    "除了端到端的训练，人们正在经历从参数统计描述到完全非参数模型的转变。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1eb739c-a9d1-47e7-b10f-de24ccda2bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
